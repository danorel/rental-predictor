{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pp\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = [\n",
    "    'year',\n",
    "    'floor',\n",
    "    'rooms',\n",
    "    'total_area',\n",
    "    'living_area',\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'description',\n",
    "    'image_urls'\n",
    "]\n",
    "\n",
    "BOOLEAN_FEATURES = [\n",
    "    'price_verification',\n",
    "    'apartment_verification'\n",
    "]\n",
    "\n",
    "CATEGORIAL_FEATURES = [\n",
    "    'heating',\n",
    "    'walls',\n",
    "    'region',\n",
    "    'city',\n",
    "]\n",
    "\n",
    "TARGET = 'price'\n",
    "\n",
    "SUBSTITUTE_FEATURES = [\n",
    "    'description',\n",
    "    'image_urls'\n",
    "]\n",
    "\n",
    "USELESS_FEATURES = [\n",
    "    'title',\n",
    "    'seller',\n",
    "    'street',\n",
    "    'publish_date',\n",
    "    'offer_id',\n",
    "    'apartment_id'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_X_y(\n",
    "        df,\n",
    "        target\n",
    "):\n",
    "    \"\"\"\n",
    "    Get numpy arrays from pandas data frame\n",
    "    :type df: pd.DataFrame\n",
    "    :type target: str\n",
    "    \"\"\"\n",
    "    return np.array(df.loc[:, df.columns != target]), np.array(df.loc[:, df.columns == target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "        csv,\n",
    "        target,\n",
    "        categorial_features,\n",
    "        boolean_features,\n",
    "        numerical_features,\n",
    "        useless_features,\n",
    "        substitute_features\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Load the dataset, preprocess it, split it in X, y numpy variables\n",
    "    :type csv: str\n",
    "    :type target: str\n",
    "    :type categorial_features: list\n",
    "    :type boolean_features: list\n",
    "    :type numerical_features: list\n",
    "    :type useless_features: list\n",
    "    :type substitute_features: list\n",
    "    \"\"\"\n",
    "    print(\"Collecting the data from csv file...\")\n",
    "    df = pd.read_csv(csv)\n",
    "    print(\"Substituting the features...\")\n",
    "    df = substitute(\n",
    "        df=df,\n",
    "        substitute_features=substitute_features\n",
    "    )\n",
    "    print(\"Dropping the useless features...\")\n",
    "    df.drop(\n",
    "        columns=useless_features,\n",
    "        inplace=True\n",
    "    )\n",
    "    print(\"Filling the NA values...\")\n",
    "    df.fillna(\n",
    "        value=df.mean(),\n",
    "        inplace=True\n",
    "    )\n",
    "    print(\"Scaling the numeric features...\")\n",
    "    df = scale_features(\n",
    "        df=df,\n",
    "        numeric_features=numerical_features\n",
    "    )\n",
    "    print(\"Performing one-hot-encoding...\")\n",
    "    df = pd.get_dummies(\n",
    "        data=df,\n",
    "        columns=(categorial_features + boolean_features),\n",
    "    )\n",
    "#     print(\"Extracting the X, y features from the pandas DataFrame object...\")\n",
    "#     X, y = extract_X_y(\n",
    "#         df=df,\n",
    "#         target=target\n",
    "#     )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(\n",
    "        df,\n",
    "        numeric_features\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scale the numerical features and return the pandas data frame with that modifications\n",
    "    :type df: pd.DataFrame\n",
    "    :type numeric_features: list\n",
    "    \"\"\"\n",
    "    scaled_features = df[numeric_features]\n",
    "    scaled_features = StandardScaler() \\\n",
    "        .fit_transform(scaled_features)\n",
    "    df[numeric_features] = scaled_features\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute(\n",
    "        df,\n",
    "        substitute_features\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Substitute features with len property\n",
    "    :type df: pd.DataFrame\n",
    "    :type substitute_features: list\n",
    "    \"\"\"\n",
    "    for feature in substitute_features:\n",
    "        df[feature] = df[feature].map(lambda value: feature_to_len(feature, value))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_to_len(\n",
    "        feature,\n",
    "        value\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract the length of the feature\n",
    "    :type feature: object\n",
    "    \"\"\"\n",
    "    if not isinstance(value, object) or pd.isna(value) or pd.isnull(value):\n",
    "        return 0\n",
    "    if feature == 'description':\n",
    "        return len(str(value))\n",
    "    if feature == 'image_urls':\n",
    "        value = str(value)\n",
    "        value = ast.literal_eval(value)\n",
    "        return len(value)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting the data from csv file...\n",
      "Substituting the features...\n",
      "Dropping the useless features...\n",
      "Filling the NA values...\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(\n",
    "    csv='data.csv',\n",
    "    target=TARGET,\n",
    "    categorial_features=CATEGORIAL_FEATURES,\n",
    "    boolean_features=BOOLEAN_FEATURES,\n",
    "    numerical_features=NUMERICAL_FEATURES,\n",
    "    useless_features=USELESS_FEATURES,\n",
    "    substitute_features=SUBSTITUTE_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
